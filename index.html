<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Portfolio of Amol S. Joshi, PhD candidate in machine learning and computer vision">
  <meta name="keywords" content="machine learning, deep learning, computer vision, Python, PyTorch">
  <title>Amol S. Joshi - Machine Learning Portfolio</title>
  <script src="https://cdn.jsdelivr.net/npm/react@18.2.0/umd/react.production.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/react-dom@18.2.0/umd/react-dom.production.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <style>
    .highlight { color: #404040; font-weight: bold; }
    a { color: #000080; text-decoration: underline; }
    a:hover { color: #1e3a8a; }
    section { scroll-margin-top: 80px; }
    body { font-family: 'Inter', sans-serif; }
  </style>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body class="bg-white text-gray-800">
  <div id="root"></div>
  <script type="text/babel">
    const App = () => {
      return (
        <div>
          {/* Header                  <a href="#skills" class="hover:text-blue-800">Skills</a>  */}
          <header class="bg-gray-100 fixed top-0 w-full shadow-md z-10">
            <nav class="container mx-auto px-4 py-4 flex justify-between items-center">
              <h1 class="text-2xl font-bold">Amol S. Joshi</h1>
              <div class="space-x-4">
                <a href="#about" class="hover:text-blue-800">About</a>
                <a href="#projects" class="hover:text-blue-800">Projects</a>
              
                <a href="#contact" class="hover:text-blue-800">Contact</a>
              </div>
            </nav>
          </header>

          {/* About */}
          <section id="about" class="container mx-auto px-4 py-20">
            <h2 class="text-3xl font-bold mb-4">About</h2>
            {/*<p class="text-lg max-w-2xl">
              PhD candidate in Computer Science at West Virginia University, specializing in <span class="highlight">deep learning</span> and <span class="highlight">computer vision</span>. Experienced in developing <span class="highlight">GAN</span>-based models and synthetic data generation, with a patent pending for an innovative image deblurring algorithm.
            </p>*/}
            
            <p class="text-lg max-w-3xl">
              I am a machine learning researcher and Ph.D. student specializing in deep learning for biometrics and computer vision. As part of my doctoral research at West Virginia University under the guidance of Dr. Jeremy Dawson, I focus on optimizing the recognition fingerphotos and latent fingerprints using advanced generative models and self-supervised learning frameworks.
            </p>
            <br/>
            <p class="text-lg max-w-3xl">
              I hold a Bachelor's degree in Computer Science from Pune University and a Master's in Information Technology from Sikkim Manipal University DDE. My work bridges research and practical solutions, with contributions to both academic and industry projects involving Python, C/C++, C#, SQL, and cloud technologies like Google Cloud and Microsoft Azure.
            </p>
            <br/>
            <p class="text-lg max-w-3xl">
              My recent projects include a pending patent for a GAN-based image deblurring algorithm, quality assessment frameworks for biometric data, style transfer techniques for latent fingerprint enhancement, and synthetic data generation methods to tackle data scarcity in biometrics.
            </p>
            <br/>
            <p class="text-lg max-w-3xl">
              Beyond research, I enjoy playing the flute and listening to Indian classical music to unwind and find inspiration. Feel free to explore my portfolio and reach out if you'd like to connect or collaborate.
            </p>


          </section>

          {/* Projects */}
          <section id="projects" class="bg-gray-100 py-20">
            <div class="container mx-auto px-4">
              <h2 class="text-3xl font-bold mb-8">Projects</h2>
              <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/project1.png" alt="Fingerphoto Deblurring" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">Fingerphoto Deblurring Using Attention-guided Multi-stage <span class="highlight">GAN</span></h3>
                  <p class="mb-2"><span class="highlight">FDeblurGAN (Fingerphoto Deblurring)</span> was a multi-stage deep GAN-based algorithm designed and implemented to restore blurred fingerphotos using a multi-stage, attention-based conditional GAN architecture.</p>
                  <p>I evaluated the verification performance of the deblurred fingerphotos against their corresponding ground truth sharp images using two different fingerprint verifiers. The proposed method was compared with a state-of-the-art deblurring algorithm (DeblurGAN-v2) and achieved approximately a 14% improvement in AUC. A patent for this algorithm is pending.</p>
                  <p class="text-sm"><a href="https://arxiv.org/pdf/2106.11354" aria-label="Paper I for Fingerphoto Deblurring">Paper I</a> | <a href="https://ieeexplore.ieee.org/abstract/document/10201840" aria-label="Paper II for Fingerphoto Deblurring">Paper II</a></p>
                </div>
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/project2.png" alt="UFQA Quality Assessment" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">UFQA: Utility-guided Fingerphoto Quality Assessment</h3>
                  <p class="mb-2"><span class="highlight">UFQA (Utility-guided Fingerphoto Quality Assessment)</span> proposed a self-supervised dual encoder framework with a fusion module and a quality prediction network to estimate fingerphoto quality as a predictor of recognition utility.</p>
                  <p>I designed a holistic labeling process that considered both image characteristics and identity information to train the model effectively. The method was evaluated on multiple publicly available datasets and demonstrated improved performance compared to three existing image quality assessment (IQA) algorithms.</p>
                  <p class="text-sm"><a href="https://arxiv.org/pdf/2407.11141" aria-label="Paper for UFQA">Paper</a></p>
                </div>
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/project3.png" alt="Synthetic Fingerprint Generation" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">Synthetic Latent Fingerprint Generation Using Style Transfer</h3>
                  <p class="mb-2"><span class="highlight">Latent Fingerprint Style Transfer</span> explored enhancing latent fingerprint images by transferring realistic ridge patterns. In this approach, a pair of a fingerprint and a real latent fingerprint were used as the content and style images, respectively. A pre-trained network extracted features from these inputs, and the style features were fused with the content features to generate a stylized feature representation.</p>
                  <p> A decoder was then trained to reconstruct the stylized image from the fused features, producing latent fingerprints with clearer ridge patterns matching the style of the input latent image. This technique improved the visual quality and recognizability of latent fingerprints for further biometric processing.</p>
                  <p class="text-sm"><a href="https://arxiv.org/pdf/2309.15734" aria-label="Paper for Synthetic Fingerprint">Paper</a></p>
                </div>
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/project4.png" alt="Image Enhancement" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">Latent Fingerprint Enhancement</h3>
                  <p class="mb-2"><span class="highlight">Latent Fingerprint Enhancement</span> focused on improving the clarity and recognition accuracy of low-quality latent fingerprints. I designed an enhancement algorithm and generated realistic synthetic latent fingerprints to train the model effectively. A multi-task GAN was trained to enhance latent fingerprints, and its performance was evaluated against several publicly available datasets, showing improvements over state-of-the-art enhancement methods.</p>
                  <p>I further evaluated the accuracy of detected minutiae points on both the original and enhanced fingerprints and verified the improvement in image quality metrics after enhancement.</p>
                </div>
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/cmpa_logo.png" alt="Cmpa" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">CMPA</h3>
                  <p class="mb-2"><span class="highlight">CMPA (Computer Vision and Machine Learning-based Platform for Agrochemicals)</span> is an Android application designed to scan and read agrochemical product labels using optical character recognition (OCR). During development, I explored and evaluated various APIs, including Tesseract and the Microsoft Computer Vision API, to achieve accurate text extraction. The final implementation integrates the Google Vision API to reliably recognize text on product labels in real time.</p>
                  <p>This project was shortlisted at the IUPAC Summit.</p>
                  <p class="text-sm"><a href="https://nextgeniupac2019.wordpress.com/2019/03/12/responsible-use-of-agrochemicals/" aria-label="GitHub for Satellite Imagery">GitHub</a></p>
                </div>
                <div class="bg-white p-6 rounded-lg shadow-md">
                  <div class="relative w-full aspect-[4/3] overflow-hidden rounded-md mb-4">
                    <img src="/images/data_sample.png" alt="Satellite Imagery in Agriculture" class="absolute inset-0 w-full h-full object-cover" />
                  </div>
                    <h3 class="text-xl font-semibold mb-2">Satellite Imagery in Agriculture</h3>
                  <p class="mb-2"><span class="highlight">Satellite imagery for precision agriculture</span> was an initiative aimed at supporting precision and sustainable farming practices to improve farmers' socio-economic status. It began with grape farmers in India and incorporated real on-field insights to develop smart decision-making tools for water, fertilizer, pesticide, and disease management.</p>
                  <p>A key challenge addressed was the presence of clouds in satellite imagery, which disrupted the calculation of vital agricultural indices. To overcome this, I created a custom labeled dataset of over 3,500 Sentinel-2 images and trained a U-Net segmentation model to accurately generate cloud masks. I also experimented with hyperparameter tuning and transfer learning to improve accuracy and mIoU for reliable cloud removal.</p>
                </div>
              </div>
            </div>
          </section>

          {/* Skills */}
          {/* <section id="skills" class="container mx-auto px-4 py-20">
            <h2 class="text-3xl font-bold mb-8">Skills</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-4 max-w-2xl">
              <div class="flex">
                <span class="w-32 font-semibold">Languages:</span>
                <span><span class="highlight">Python</span>, C#, SQL</span>
              </div>
              <div class="flex">
                <span class="w-32 font-semibold">Libraries:</span>
                <span><span class="highlight">PyTorch</span>, PyTorch Lightning, <span class="highlight">Scikit-Learn</span>, OpenCV</span>
              </div>
              <div class="flex">
                <span class="w-32 font-semibold">Tools:</span>
                <span><span class="highlight">Git</span>, Azure, AWS, Docker</span>
              </div>
            </div>
          </section> */}

          {/* Contact */}
          <section id="contact" class="bg-gray-100 py-20">
            <div class="container mx-auto px-4">
              <h2 class="text-3xl font-bold mb-8">Contact</h2>
              <div class="flex flex-col space-y-2">
                <a href="https://github.com/ajoshi944">GitHub Profile</a>
                <a href="https://linkedin.com/in/ajoshi944">LinkedIn Profile</a>
                <a href="mailto:asj00003@mix.wvu.edu">Email: asj00003@mix.wvu.edu</a>
                <a href="/resume.pdf">Download Resume</a>
              </div>
            </div>
          </section>

          {/* Footer */}
          <footer class="bg-gray-800 text-white text-center py-4">
            <p>© 2025 Amol S. Joshi</p>
          </footer>
        </div>
      );
    };

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<App />);
  </script>
</body>
</html>